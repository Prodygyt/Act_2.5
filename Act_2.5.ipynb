{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pjxJEKLez-QV"
      },
      "outputs": [],
      "source": [
        "#Importamos las librerias necesarias para el experimento\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Importamos el dataset que vamos a utilizar para los experimento\n",
        "from tensorflow.keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teXPhxmg8aW0"
      },
      "source": [
        "### Data set seleccionado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "_lNYFiNd6cLQ",
        "outputId": "d5d5a335-24f4-49b1-a66b-a7e2219dbc39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1us/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Dividimos los datos donde X son los datos pertenecientes al dataset importado y Y son las etiquetas de entrenamiento\n",
        "(xtrain, ytrain), (xtest, ytest) = cifar10.load_data()\n",
        "\n",
        "#Se comprueba que se hizo la separación de forma correcta\n",
        "plt.imshow(xtrain[20])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJPMqH0F8jUP"
      },
      "source": [
        "### Pre procesamiento de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9hAY7GHX86LK"
      },
      "outputs": [],
      "source": [
        "# Normalización de los datos\n",
        "xtrain = xtrain.astype('float32') / 255\n",
        "xtest = xtest.astype('float32') / 255\n",
        "\n",
        "# Convirtiendo las etiquetas de las variables y_train y y_test a una representación one-hot encoding utilizando la biblioteca Keras de TensorFlow.\n",
        "ytrain = tf.keras.utils.to_categorical(ytrain, num_classes=10)\n",
        "ytest = tf.keras.utils.to_categorical(ytest, num_classes=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4UY7GoxA8SP"
      },
      "source": [
        "### Definición del Modelo CNN base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wyeqXPNMBAqM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Aaron Urbina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "#Modelo base\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cONW3ZzsERtv"
      },
      "source": [
        "### Compilación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RHlWMxWxERRn"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdOhNwvCA3H"
      },
      "source": [
        "### Experimento 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU-Kyy8SCjIN",
        "outputId": "1cd894d1-8bcc-41a6-91b8-85e38ff110e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.3555 - loss: 1.7939 - val_accuracy: 0.5279 - val_loss: 1.3494\n",
            "Epoch 2/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.5462 - loss: 1.2938 - val_accuracy: 0.5736 - val_loss: 1.2125\n",
            "Epoch 3/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.5926 - loss: 1.1629 - val_accuracy: 0.5951 - val_loss: 1.1567\n",
            "Epoch 4/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.6294 - loss: 1.0673 - val_accuracy: 0.6101 - val_loss: 1.1144\n",
            "Epoch 5/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.6392 - loss: 1.0290 - val_accuracy: 0.6231 - val_loss: 1.0859\n",
            "Epoch 6/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.6632 - loss: 0.9668 - val_accuracy: 0.6380 - val_loss: 1.0544\n",
            "Epoch 7/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.6830 - loss: 0.9198 - val_accuracy: 0.6407 - val_loss: 1.0491\n",
            "Epoch 8/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.6951 - loss: 0.8761 - val_accuracy: 0.6479 - val_loss: 1.0199\n",
            "Epoch 9/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.7116 - loss: 0.8371 - val_accuracy: 0.6525 - val_loss: 1.0191\n",
            "Epoch 10/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7161 - loss: 0.8116 - val_accuracy: 0.6539 - val_loss: 1.0289\n"
          ]
        }
      ],
      "source": [
        "#Entrenamiento del Modelo\n",
        "history = model.fit(xtrain, ytrain, epochs=10, batch_size= 128, validation_data = (xtest, ytest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph4mJOMwFTeS",
        "outputId": "e170e1d6-bc0d-496a-e16f-b2066c7905d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6574 - loss: 1.0166\n",
            "Test accuracy: 0.6539000272750854\n"
          ]
        }
      ],
      "source": [
        "#Evaluación del modelo\n",
        "test_loss, test_acc = model.evaluate(xtest, ytest)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spjtRsnGJwt2"
      },
      "source": [
        "### Experimento 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EN5QjTdYK9uL"
      },
      "outputs": [],
      "source": [
        "#Modificando el modelo agregando más capas convolucionales, aumentando el número de filtros y agregando una capa dropout\n",
        "modelV2 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBOVK7rXMQsO",
        "outputId": "72d2b3d9-0106-4647-96a3-be746a27bc8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.2589 - loss: 1.9737 - val_accuracy: 0.4913 - val_loss: 1.4180\n",
            "Epoch 2/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.4795 - loss: 1.4419 - val_accuracy: 0.5672 - val_loss: 1.2248\n",
            "Epoch 3/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.5421 - loss: 1.2776 - val_accuracy: 0.5949 - val_loss: 1.1350\n",
            "Epoch 4/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.5881 - loss: 1.1717 - val_accuracy: 0.6219 - val_loss: 1.0755\n",
            "Epoch 5/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.6145 - loss: 1.1003 - val_accuracy: 0.6511 - val_loss: 0.9909\n",
            "Epoch 6/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.6422 - loss: 1.0161 - val_accuracy: 0.6631 - val_loss: 0.9523\n",
            "Epoch 7/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.6652 - loss: 0.9631 - val_accuracy: 0.6631 - val_loss: 0.9544\n",
            "Epoch 8/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.6817 - loss: 0.9191 - val_accuracy: 0.6812 - val_loss: 0.9034\n",
            "Epoch 9/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.6975 - loss: 0.8632 - val_accuracy: 0.6826 - val_loss: 0.9032\n",
            "Epoch 10/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.7131 - loss: 0.8249 - val_accuracy: 0.6777 - val_loss: 0.9176\n"
          ]
        }
      ],
      "source": [
        "#Compilación del modelo modificado\n",
        "modelV2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Entrenamiento del modelo modificado\n",
        "historyV2 = modelV2.fit(xtrain, ytrain, epochs=10, batch_size= 128, validation_data = (xtest, ytest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB0AyEQKOeo8",
        "outputId": "8a5e5bbc-612e-4cb4-fa9c-aa3cc351b41c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6829 - loss: 0.9049\n",
            "Test accuracy (modelo modificado): 0.6776999831199646\n"
          ]
        }
      ],
      "source": [
        "#Evaluar el modelo modificado\n",
        "test_lossV2, test_accV2 = modelV2.evaluate(xtest, ytest)\n",
        "print('Test accuracy (modelo modificado):', test_accV2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdCPL_4IO7A4"
      },
      "source": [
        "Experimento 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftVnOmalPP-s",
        "outputId": "66a5eed7-90a5-45d3-9b3e-376ce0526a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.2231 - loss: 2.0905 - val_accuracy: 0.4130 - val_loss: 1.6531\n",
            "Epoch 2/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3941 - loss: 1.6606 - val_accuracy: 0.4615 - val_loss: 1.4900\n",
            "Epoch 3/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4428 - loss: 1.5260 - val_accuracy: 0.5146 - val_loss: 1.3691\n",
            "Epoch 4/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4904 - loss: 1.4195 - val_accuracy: 0.5339 - val_loss: 1.3057\n",
            "Epoch 5/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5119 - loss: 1.3618 - val_accuracy: 0.5458 - val_loss: 1.2570\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5494 - loss: 1.2567\n",
            "Epoch 1/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2136 - loss: 2.0949 - val_accuracy: 0.4232 - val_loss: 1.6166\n",
            "Epoch 2/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3851 - loss: 1.6631 - val_accuracy: 0.4811 - val_loss: 1.4489\n",
            "Epoch 3/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4432 - loss: 1.5220 - val_accuracy: 0.5062 - val_loss: 1.3671\n",
            "Epoch 4/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4751 - loss: 1.4443 - val_accuracy: 0.5268 - val_loss: 1.3166\n",
            "Epoch 5/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5047 - loss: 1.3719 - val_accuracy: 0.5437 - val_loss: 1.2622\n",
            "Epoch 6/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5290 - loss: 1.3164 - val_accuracy: 0.5703 - val_loss: 1.2108\n",
            "Epoch 7/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5423 - loss: 1.2796 - val_accuracy: 0.5848 - val_loss: 1.1851\n",
            "Epoch 8/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5580 - loss: 1.2432 - val_accuracy: 0.5995 - val_loss: 1.1439\n",
            "Epoch 9/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5769 - loss: 1.2009 - val_accuracy: 0.6040 - val_loss: 1.1244\n",
            "Epoch 10/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5811 - loss: 1.1780 - val_accuracy: 0.6143 - val_loss: 1.0987\n",
            "Epoch 11/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6036 - loss: 1.1342 - val_accuracy: 0.6169 - val_loss: 1.0911\n",
            "Epoch 12/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6132 - loss: 1.1049 - val_accuracy: 0.6304 - val_loss: 1.0392\n",
            "Epoch 13/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6184 - loss: 1.0894 - val_accuracy: 0.6300 - val_loss: 1.0529\n",
            "Epoch 14/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6318 - loss: 1.0519 - val_accuracy: 0.6252 - val_loss: 1.0436\n",
            "Epoch 15/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6397 - loss: 1.0365 - val_accuracy: 0.6513 - val_loss: 0.9878\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6480 - loss: 0.9871\n",
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.1760 - loss: 2.1977 - val_accuracy: 0.3535 - val_loss: 1.8041\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.3187 - loss: 1.8219 - val_accuracy: 0.4146 - val_loss: 1.6427\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.3737 - loss: 1.6976 - val_accuracy: 0.4558 - val_loss: 1.5360\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.4103 - loss: 1.6017 - val_accuracy: 0.4763 - val_loss: 1.4652\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.4344 - loss: 1.5415 - val_accuracy: 0.4927 - val_loss: 1.4171\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4964 - loss: 1.4169\n",
            "Epoch 1/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.1633 - loss: 2.2208 - val_accuracy: 0.3496 - val_loss: 1.8425\n",
            "Epoch 2/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.3166 - loss: 1.8492 - val_accuracy: 0.4119 - val_loss: 1.6427\n",
            "Epoch 3/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.3743 - loss: 1.6936 - val_accuracy: 0.4450 - val_loss: 1.5515\n",
            "Epoch 4/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.4131 - loss: 1.6093 - val_accuracy: 0.4656 - val_loss: 1.4908\n",
            "Epoch 5/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.4309 - loss: 1.5515 - val_accuracy: 0.4918 - val_loss: 1.4222\n",
            "Epoch 6/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.4570 - loss: 1.4955 - val_accuracy: 0.5069 - val_loss: 1.3902\n",
            "Epoch 7/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.4767 - loss: 1.4534 - val_accuracy: 0.5194 - val_loss: 1.3509\n",
            "Epoch 8/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.4883 - loss: 1.4119 - val_accuracy: 0.5251 - val_loss: 1.3369\n",
            "Epoch 9/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.4959 - loss: 1.3894 - val_accuracy: 0.5370 - val_loss: 1.2942\n",
            "Epoch 10/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.5135 - loss: 1.3569 - val_accuracy: 0.5470 - val_loss: 1.2736\n",
            "Epoch 11/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.5199 - loss: 1.3332 - val_accuracy: 0.5588 - val_loss: 1.2482\n",
            "Epoch 12/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.5274 - loss: 1.3150 - val_accuracy: 0.5580 - val_loss: 1.2327\n",
            "Epoch 13/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.5389 - loss: 1.2905 - val_accuracy: 0.5699 - val_loss: 1.2138\n",
            "Epoch 14/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.5500 - loss: 1.2671 - val_accuracy: 0.5743 - val_loss: 1.1993\n",
            "Epoch 15/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.5545 - loss: 1.2464 - val_accuracy: 0.5803 - val_loss: 1.1877\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5874 - loss: 1.1831\n",
            "Epoch 1/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.3001 - loss: 1.8688 - val_accuracy: 0.5302 - val_loss: 1.3010\n",
            "Epoch 2/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5268 - loss: 1.3207 - val_accuracy: 0.6059 - val_loss: 1.1205\n",
            "Epoch 3/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5926 - loss: 1.1535 - val_accuracy: 0.6066 - val_loss: 1.1333\n",
            "Epoch 4/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6359 - loss: 1.0483 - val_accuracy: 0.6610 - val_loss: 0.9707\n",
            "Epoch 5/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6689 - loss: 0.9552 - val_accuracy: 0.6485 - val_loss: 1.0008\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6514 - loss: 0.9956\n",
            "Epoch 1/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.2894 - loss: 1.8922 - val_accuracy: 0.5178 - val_loss: 1.3529\n",
            "Epoch 2/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5212 - loss: 1.3332 - val_accuracy: 0.5827 - val_loss: 1.1598\n",
            "Epoch 3/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5917 - loss: 1.1577 - val_accuracy: 0.6272 - val_loss: 1.0480\n",
            "Epoch 4/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6337 - loss: 1.0460 - val_accuracy: 0.6667 - val_loss: 0.9441\n",
            "Epoch 5/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6661 - loss: 0.9564 - val_accuracy: 0.6855 - val_loss: 0.8977\n",
            "Epoch 6/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6891 - loss: 0.8910 - val_accuracy: 0.6792 - val_loss: 0.9110\n",
            "Epoch 7/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7040 - loss: 0.8436 - val_accuracy: 0.6936 - val_loss: 0.8944\n",
            "Epoch 8/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7239 - loss: 0.7902 - val_accuracy: 0.7145 - val_loss: 0.8357\n",
            "Epoch 9/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7418 - loss: 0.7507 - val_accuracy: 0.7117 - val_loss: 0.8365\n",
            "Epoch 10/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7496 - loss: 0.7195 - val_accuracy: 0.7179 - val_loss: 0.8259\n",
            "Epoch 11/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7597 - loss: 0.6917 - val_accuracy: 0.7150 - val_loss: 0.8533\n",
            "Epoch 12/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7706 - loss: 0.6602 - val_accuracy: 0.7104 - val_loss: 0.8678\n",
            "Epoch 13/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7746 - loss: 0.6413 - val_accuracy: 0.7173 - val_loss: 0.8559\n",
            "Epoch 14/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7837 - loss: 0.6152 - val_accuracy: 0.7174 - val_loss: 0.8684\n",
            "Epoch 15/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7960 - loss: 0.5883 - val_accuracy: 0.7232 - val_loss: 0.8453\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.8313\n",
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.2589 - loss: 1.9711 - val_accuracy: 0.4645 - val_loss: 1.4494\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.4671 - loss: 1.4689 - val_accuracy: 0.5362 - val_loss: 1.2967\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.5333 - loss: 1.3046 - val_accuracy: 0.5909 - val_loss: 1.1446\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.5786 - loss: 1.1876 - val_accuracy: 0.6157 - val_loss: 1.0752\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.6164 - loss: 1.0897 - val_accuracy: 0.6424 - val_loss: 1.0163\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6471 - loss: 1.0133\n",
            "Epoch 1/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.2571 - loss: 1.9785 - val_accuracy: 0.4991 - val_loss: 1.3907\n",
            "Epoch 2/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.4787 - loss: 1.4484 - val_accuracy: 0.5707 - val_loss: 1.2193\n",
            "Epoch 3/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.5489 - loss: 1.2748 - val_accuracy: 0.6005 - val_loss: 1.1125\n",
            "Epoch 4/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.5957 - loss: 1.1472 - val_accuracy: 0.6351 - val_loss: 1.0402\n",
            "Epoch 5/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.6304 - loss: 1.0631 - val_accuracy: 0.6555 - val_loss: 0.9737\n",
            "Epoch 6/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.6533 - loss: 0.9835 - val_accuracy: 0.6696 - val_loss: 0.9450\n",
            "Epoch 7/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.6741 - loss: 0.9312 - val_accuracy: 0.6808 - val_loss: 0.9155\n",
            "Epoch 8/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.6917 - loss: 0.8838 - val_accuracy: 0.6904 - val_loss: 0.8828\n",
            "Epoch 9/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.7053 - loss: 0.8538 - val_accuracy: 0.6978 - val_loss: 0.8626\n",
            "Epoch 10/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.7175 - loss: 0.8131 - val_accuracy: 0.7031 - val_loss: 0.8479\n",
            "Epoch 11/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.7276 - loss: 0.7843 - val_accuracy: 0.7058 - val_loss: 0.8477\n",
            "Epoch 12/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.7436 - loss: 0.7342 - val_accuracy: 0.6990 - val_loss: 0.8666\n",
            "Epoch 13/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.7489 - loss: 0.7236 - val_accuracy: 0.7151 - val_loss: 0.8260\n",
            "Epoch 14/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.7614 - loss: 0.6918 - val_accuracy: 0.7143 - val_loss: 0.8345\n",
            "Epoch 15/15\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.7705 - loss: 0.6582 - val_accuracy: 0.7264 - val_loss: 0.7924\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.7882\n",
            "Mejor precisión:  0.7264000177383423\n",
            "Mejores parametros;  (0.001, 128, 15)\n"
          ]
        }
      ],
      "source": [
        "#Definición de los valores de los hiperparámetros a explorar\n",
        "\n",
        "learning_rates = [0.0001, 0.001]\n",
        "batch_sizes = [32, 128]\n",
        "epochs = [5, 15]\n",
        "\n",
        "best_acc = 0\n",
        "best_params = None\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for bsz in batch_sizes:\n",
        "        for ep in epochs:\n",
        "            model = Sequential([\n",
        "                Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "                MaxPooling2D((2, 2)),\n",
        "                Conv2D(64, (3, 3), activation='relu'),\n",
        "                MaxPooling2D((2, 2)),\n",
        "                Conv2D(128, (3, 3), activation='relu'),\n",
        "                MaxPooling2D((2, 2)),\n",
        "                Flatten(),\n",
        "                Dense(128, activation='relu'),\n",
        "                tf.keras.layers.Dropout(0.5),\n",
        "                Dense(10, activation='softmax')\n",
        "                ])\n",
        "            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "            model.fit(xtrain, ytrain, epochs=ep, batch_size=bsz, validation_data=(xtest, ytest))\n",
        "\n",
        "            test_loss, test_acc = model.evaluate(xtest, ytest)\n",
        "\n",
        "            if test_acc > best_acc:\n",
        "              best_acc = test_acc\n",
        "              best_params = (lr,bsz,ep)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Mejor precisión: \", best_acc)\n",
        "print(\"Mejores parametros; \", best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "D6KE6INpUL_F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor precisión:  0.7264000177383423\n",
            "Mejores parametros;  (0.001, 128, 15)\n"
          ]
        }
      ],
      "source": [
        "#Evaluación del modelo con el mejor conjunto de parametros\n",
        "print(\"Mejor precisión: \", best_acc)\n",
        "print(\"Mejores parametros; \", best_params)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
